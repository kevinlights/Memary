{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install -qU langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "# Optional, uncomment to trace runs with LangSmith. Sign up here: https://smith.langchain.com.\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from typing import Literal, Optional, Tuple\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class SubQuery(BaseModel):\n",
    "    \"\"\"Search over a database of tutorial videos about a software library.\"\"\"\n",
    "\n",
    "    sub_query: str = Field(\n",
    "        ...,\n",
    "        description=\"A very specific query against the database.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticToolsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "system = \"\"\"You are an expert at converting user questions into database queries. \\\n",
    "You have access to a database of tutorial videos about a software library for building LLM-powered applications. \\\n",
    "\n",
    "Perform query decomposition. Given a user question, break it down into distinct sub questions that \\\n",
    "you need to answer in order to answer the original question.\n",
    "\n",
    "If there are acronyms or words you are not familiar with, do not try to rephrase them.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "llm = ChatOpenAI(model=\"qwen2.5:14b\", temperature=0, base_url=\"http://localhost:11434/v1\", api_key=\"sk-xxx\")\n",
    "llm_with_tools = llm.bind_tools([SubQuery])\n",
    "parser = PydanticToolsParser(tools=[SubQuery])\n",
    "query_analyzer = prompt | llm_with_tools | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SubQuery(sub_query='What is RAG?')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke({\"question\": \"how to do rag\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SubQuery(sub_query='how to create a chain using multi-modal models'),\n",
       " SubQuery(sub_query='how to turn a chain into a rest api')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\n",
    "    {\n",
    "        \"question\": \"how to use multi-modal models in a chain and turn chain into a rest api\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "question = \"What's chat langchain, is it a langchain template?\"\n",
    "queries = [\n",
    "    SubQuery(sub_query=\"What is chat langchain\"),\n",
    "    SubQuery(sub_query=\"What is a langchain template\"),\n",
    "]\n",
    "examples.append({\"input\": question, \"tool_calls\": queries})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How would I use LangGraph to build an automaton\"\n",
    "queries = [\n",
    "    SubQuery(sub_query=\"How to build automaton with LangGraph\"),\n",
    "]\n",
    "examples.append({\"input\": question, \"tool_calls\": queries})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How to build multi-agent system and stream intermediate steps from it\"\n",
    "queries = [\n",
    "    SubQuery(sub_query=\"How to build multi-agent system\"),\n",
    "    SubQuery(sub_query=\"How to stream intermediate steps\"),\n",
    "    SubQuery(sub_query=\"How to stream intermediate steps from multi-agent system\"),\n",
    "]\n",
    "examples.append({\"input\": question, \"tool_calls\": queries})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What's the difference between LangChain agents and LangGraph?\"\n",
    "queries = [\n",
    "    SubQuery(sub_query=\"What's the difference between LangChain agents and LangGraph?\"),\n",
    "    SubQuery(sub_query=\"What are LangChain agents\"),\n",
    "    SubQuery(sub_query=\"What is LangGraph\"),\n",
    "]\n",
    "examples.append({\"input\": question, \"tool_calls\": queries})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is the teacher standing in front of the classroom while giving a lecture or conducting an activity?\"\n",
    "queries = [\n",
    "    SubQuery(sub_query=\"Is the teacher standing in front of the classroom?\"),\n",
    "    SubQuery(sub_query=\"Is the teacher giving a lecture or conducting an activity?\"),\n",
    "]\n",
    "\n",
    "examples.append({\"input\": question, \"tool_calls\": queries})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': \"What's chat langchain, is it a langchain template?\",\n",
       "  'tool_calls': [SubQuery(sub_query='What is chat langchain'),\n",
       "   SubQuery(sub_query='What is a langchain template')]},\n",
       " {'input': 'How would I use LangGraph to build an automaton',\n",
       "  'tool_calls': [SubQuery(sub_query='How to build automaton with LangGraph')]},\n",
       " {'input': 'How to build multi-agent system and stream intermediate steps from it',\n",
       "  'tool_calls': [SubQuery(sub_query='How to build multi-agent system'),\n",
       "   SubQuery(sub_query='How to stream intermediate steps'),\n",
       "   SubQuery(sub_query='How to stream intermediate steps from multi-agent system')]},\n",
       " {'input': \"What's the difference between LangChain agents and LangGraph?\",\n",
       "  'tool_calls': [SubQuery(sub_query=\"What's the difference between LangChain agents and LangGraph?\"),\n",
       "   SubQuery(sub_query='What are LangChain agents'),\n",
       "   SubQuery(sub_query='What is LangGraph')]},\n",
       " {'input': 'Is the teacher standing in front of the classroom while giving a lecture or conducting an activity?',\n",
       "  'tool_calls': [SubQuery(sub_query='Is the teacher standing in front of the classroom?'),\n",
       "   SubQuery(sub_query='Is the teacher giving a lecture or conducting an activity?')]}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import Dict, List\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "\n",
    "\n",
    "def tool_example_to_messages(example: Dict) -> List[BaseMessage]:\n",
    "    messages: List[BaseMessage] = [HumanMessage(content=example[\"input\"])]\n",
    "    openai_tool_calls = []\n",
    "    for tool_call in example[\"tool_calls\"]:\n",
    "        openai_tool_calls.append(\n",
    "            {\n",
    "                \"id\": str(uuid.uuid4()),\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": tool_call.__class__.__name__,\n",
    "                    \"arguments\": tool_call.json(),\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "    messages.append(\n",
    "        AIMessage(content=\"\", additional_kwargs={\"tool_calls\": openai_tool_calls})\n",
    "    )\n",
    "    tool_outputs = example.get(\"tool_outputs\") or [\n",
    "        \"This is an example of a correct usage of this tool. Make sure to continue using the tool this way.\"\n",
    "    ] * len(openai_tool_calls)\n",
    "    for output, tool_call in zip(tool_outputs, openai_tool_calls):\n",
    "        messages.append(ToolMessage(content=output, tool_call_id=tool_call[\"id\"]))\n",
    "    return messages\n",
    "\n",
    "\n",
    "example_msgs = [msg for ex in examples for msg in tool_example_to_messages(ex)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"What's chat langchain, is it a langchain template?\"),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '2256441a-0ff7-4342-a15c-fcc0fc3cb7e8', 'type': 'function', 'function': {'name': 'SubQuery', 'arguments': '{\"sub_query\": \"What is chat langchain\"}'}}, {'id': 'c830070f-3226-4c24-814c-fe22d19e9b74', 'type': 'function', 'function': {'name': 'SubQuery', 'arguments': '{\"sub_query\": \"What is a langchain template\"}'}}]}, tool_calls=[{'name': 'SubQuery', 'args': {'sub_query': 'What is chat langchain'}, 'id': '2256441a-0ff7-4342-a15c-fcc0fc3cb7e8'}, {'name': 'SubQuery', 'args': {'sub_query': 'What is a langchain template'}, 'id': 'c830070f-3226-4c24-814c-fe22d19e9b74'}]),\n",
       " ToolMessage(content='This is an example of a correct usage of this tool. Make sure to continue using the tool this way.', tool_call_id='2256441a-0ff7-4342-a15c-fcc0fc3cb7e8'),\n",
       " ToolMessage(content='This is an example of a correct usage of this tool. Make sure to continue using the tool this way.', tool_call_id='c830070f-3226-4c24-814c-fe22d19e9b74'),\n",
       " HumanMessage(content='How would I use LangGraph to build an automaton'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '4866ac8b-5064-4af9-b3ba-354e13efc5f5', 'type': 'function', 'function': {'name': 'SubQuery', 'arguments': '{\"sub_query\": \"How to build automaton with LangGraph\"}'}}]}, tool_calls=[{'name': 'SubQuery', 'args': {'sub_query': 'How to build automaton with LangGraph'}, 'id': '4866ac8b-5064-4af9-b3ba-354e13efc5f5'}]),\n",
       " ToolMessage(content='This is an example of a correct usage of this tool. Make sure to continue using the tool this way.', tool_call_id='4866ac8b-5064-4af9-b3ba-354e13efc5f5'),\n",
       " HumanMessage(content='How to build multi-agent system and stream intermediate steps from it'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'fcda9755-a95c-45de-9dab-61edb346b9f2', 'type': 'function', 'function': {'name': 'SubQuery', 'arguments': '{\"sub_query\": \"How to build multi-agent system\"}'}}, {'id': '6029a8f1-602b-4527-a41a-baf43b912194', 'type': 'function', 'function': {'name': 'SubQuery', 'arguments': '{\"sub_query\": \"How to stream intermediate steps\"}'}}, {'id': '39b65323-5e06-4ca8-b485-714b6ef8d564', 'type': 'function', 'function': {'name': 'SubQuery', 'arguments': '{\"sub_query\": \"How to stream intermediate steps from multi-agent system\"}'}}]}, tool_calls=[{'name': 'SubQuery', 'args': {'sub_query': 'How to build multi-agent system'}, 'id': 'fcda9755-a95c-45de-9dab-61edb346b9f2'}, {'name': 'SubQuery', 'args': {'sub_query': 'How to stream intermediate steps'}, 'id': '6029a8f1-602b-4527-a41a-baf43b912194'}, {'name': 'SubQuery', 'args': {'sub_query': 'How to stream intermediate steps from multi-agent system'}, 'id': '39b65323-5e06-4ca8-b485-714b6ef8d564'}]),\n",
       " ToolMessage(content='This is an example of a correct usage of this tool. Make sure to continue using the tool this way.', tool_call_id='fcda9755-a95c-45de-9dab-61edb346b9f2'),\n",
       " ToolMessage(content='This is an example of a correct usage of this tool. Make sure to continue using the tool this way.', tool_call_id='6029a8f1-602b-4527-a41a-baf43b912194'),\n",
       " ToolMessage(content='This is an example of a correct usage of this tool. Make sure to continue using the tool this way.', tool_call_id='39b65323-5e06-4ca8-b485-714b6ef8d564'),\n",
       " HumanMessage(content=\"What's the difference between LangChain agents and LangGraph?\"),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'cc38ca77-c44b-4072-8aa9-e96412fb9d25', 'type': 'function', 'function': {'name': 'SubQuery', 'arguments': '{\"sub_query\": \"What\\'s the difference between LangChain agents and LangGraph?\"}'}}, {'id': '43c6ab99-f119-4589-a3a7-433e6cf4ae60', 'type': 'function', 'function': {'name': 'SubQuery', 'arguments': '{\"sub_query\": \"What are LangChain agents\"}'}}, {'id': '6dd98a57-02da-4ac1-99c7-b9a44512a81e', 'type': 'function', 'function': {'name': 'SubQuery', 'arguments': '{\"sub_query\": \"What is LangGraph\"}'}}]}, tool_calls=[{'name': 'SubQuery', 'args': {'sub_query': \"What's the difference between LangChain agents and LangGraph?\"}, 'id': 'cc38ca77-c44b-4072-8aa9-e96412fb9d25'}, {'name': 'SubQuery', 'args': {'sub_query': 'What are LangChain agents'}, 'id': '43c6ab99-f119-4589-a3a7-433e6cf4ae60'}, {'name': 'SubQuery', 'args': {'sub_query': 'What is LangGraph'}, 'id': '6dd98a57-02da-4ac1-99c7-b9a44512a81e'}]),\n",
       " ToolMessage(content='This is an example of a correct usage of this tool. Make sure to continue using the tool this way.', tool_call_id='cc38ca77-c44b-4072-8aa9-e96412fb9d25'),\n",
       " ToolMessage(content='This is an example of a correct usage of this tool. Make sure to continue using the tool this way.', tool_call_id='43c6ab99-f119-4589-a3a7-433e6cf4ae60'),\n",
       " ToolMessage(content='This is an example of a correct usage of this tool. Make sure to continue using the tool this way.', tool_call_id='6dd98a57-02da-4ac1-99c7-b9a44512a81e'),\n",
       " HumanMessage(content='Is the teacher standing in front of the classroom while giving a lecture or conducting an activity?'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'a85f5aa5-ba92-47b2-a0f4-9e7f4e30ca4d', 'type': 'function', 'function': {'name': 'SubQuery', 'arguments': '{\"sub_query\": \"Is the teacher standing in front of the classroom?\"}'}}, {'id': 'df60b662-6ff6-42fd-99b3-2e10609b09cc', 'type': 'function', 'function': {'name': 'SubQuery', 'arguments': '{\"sub_query\": \"Is the teacher giving a lecture or conducting an activity?\"}'}}]}, tool_calls=[{'name': 'SubQuery', 'args': {'sub_query': 'Is the teacher standing in front of the classroom?'}, 'id': 'a85f5aa5-ba92-47b2-a0f4-9e7f4e30ca4d'}, {'name': 'SubQuery', 'args': {'sub_query': 'Is the teacher giving a lecture or conducting an activity?'}, 'id': 'df60b662-6ff6-42fd-99b3-2e10609b09cc'}]),\n",
       " ToolMessage(content='This is an example of a correct usage of this tool. Make sure to continue using the tool this way.', tool_call_id='a85f5aa5-ba92-47b2-a0f4-9e7f4e30ca4d'),\n",
       " ToolMessage(content='This is an example of a correct usage of this tool. Make sure to continue using the tool this way.', tool_call_id='df60b662-6ff6-42fd-99b3-2e10609b09cc')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "system = \"\"\"You are an expert at converting user questions into database queries. \\\n",
    "You have access to a database of tutorial videos about a software library for building LLM-powered applications. \\\n",
    "\n",
    "Perform query decomposition. Given a user question, break it down into the most specific sub questions you can \\\n",
    "which will help you answer the original question. Each sub question should be about a single concept/fact/idea.\n",
    "\n",
    "If there are acronyms or words you are not familiar with, do not try to rephrase them.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        MessagesPlaceholder(\"examples\", optional=True),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "query_analyzer_with_examples = (\n",
    "    prompt.partial(examples=example_msgs) | llm_with_tools | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SubQuery(sub_query='What is the difference between Web Voyager and Reflection Agents?'),\n",
       " SubQuery(sub_query='Do Web Voyager and Reflection Agents use LangGraph?'),\n",
       " SubQuery(sub_query='What are Web Voyager?'),\n",
       " SubQuery(sub_query='What are Reflection Agents?'),\n",
       " SubQuery(sub_query='Does Web Voyager use LangGraph?'),\n",
       " SubQuery(sub_query='Do Reflection Agents use LangGraph?')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer_with_examples.invoke(\n",
    "    {\n",
    "        \"question\": \"what's the difference between web voyager and reflection agents? do they use langgraph?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], input_types={'examples': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'examples': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an expert at converting user questions into database queries. You have access to a database of tutorial videos about a software library for building LLM-powered applications. \\nPerform query decomposition. Given a user question, break it down into the most specific sub questions you can which will help you answer the original question. Each sub question should be about a single concept/fact/idea.\\n\\nIf there are acronyms or words you are not familiar with, do not try to rephrase them.')), MessagesPlaceholder(variable_name='examples', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
